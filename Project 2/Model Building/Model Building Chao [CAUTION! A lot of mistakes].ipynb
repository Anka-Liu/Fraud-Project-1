{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seprate Training Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_testing.csv', index_col=0)\n",
    "y = df['fraud_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selected after wrapper\n",
    "x = pd.read_csv('selected features.csv', index_col = 0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling fraud records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTE(random_state=0)\n",
    "x_train_os, y_train_os = os.fit_sample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635996, 25)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1253614, 25)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_os.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FDR = pd.read_csv('fdr_rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features selected by just filter, without wrapper\n",
    "fdr = df.loc[:,FDR.loc[1:25,'Field']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794996, 25)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_train, fdr_test, y_fdr_train, y_fdr_test = train_test_split(fdr, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdr_train_os, y_fdr_train_os = os.fit_sample(fdr_train, y_fdr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635996, 25)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####       model with features selected only by FDR filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539910\n",
      "         Iterations 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>     <td>0.221</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>        <td>1353728.1176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-07 21:37</td>       <td>BIC:</td>        <td>1354029.1562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>1253614</td>      <td>Log-Likelihood:</td>   <td>-6.7684e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>24</td>            <td>LL-Null:</td>       <td>-8.6894e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>1253589</td>       <td>LLR p-value:</td>       <td>0.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>          <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>11.0000</td>             <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>               <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_lag30_count</th>           <td>0.5583</td>   <td>0.0346</td>   <td>16.1230</td> <td>0.0000</td> <td>0.4905</td>  <td>0.6262</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_lag30_count</th>        <td>-0.3860</td>  <td>0.0246</td>  <td>-15.7114</td> <td>0.0000</td> <td>-0.4341</td> <td>-0.3378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_#days_since</th>           <td>-0.0020</td>  <td>0.0002</td>  <td>-11.1101</td> <td>0.0000</td> <td>-0.0023</td> <td>-0.0016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_#days_since</th>        <td>-0.0050</td>  <td>0.0001</td>  <td>-39.3055</td> <td>0.0000</td> <td>-0.0053</td> <td>-0.0048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_lag14_count</th>        <td>0.3231</td>   <td>0.0439</td>   <td>7.3631</td>  <td>0.0000</td> <td>0.2371</td>  <td>0.4092</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_lag14_count</th>           <td>0.8304</td>   <td>0.0561</td>   <td>14.7904</td> <td>0.0000</td> <td>0.7204</td>  <td>0.9405</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_lag7_count</th>         <td>-0.9523</td>  <td>0.0720</td>  <td>-13.2276</td> <td>0.0000</td> <td>-1.0934</td> <td>-0.8112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_lag7_count</th>            <td>1.4539</td>   <td>0.0771</td>   <td>18.8612</td> <td>0.0000</td> <td>1.3028</td>  <td>1.6050</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_lag3_count</th>         <td>-0.3772</td>  <td>0.1217</td>   <td>-3.0988</td> <td>0.0019</td> <td>-0.6158</td> <td>-0.1386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_lag3_count</th>            <td>1.3437</td>   <td>0.1260</td>   <td>10.6639</td> <td>0.0000</td> <td>1.0968</td>  <td>1.5907</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>address_lag1_count</th>         <td>-2.8448</td>  <td>0.3949</td>   <td>-7.2029</td> <td>0.0000</td> <td>-3.6188</td> <td>-2.0707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr_lag1_count</th>            <td>0.9755</td>   <td>0.3957</td>   <td>2.4652</td>  <td>0.0137</td> <td>0.1999</td>  <td>1.7511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr-homephone_lag30_count</th> <td>0.2699</td>   <td>0.0272</td>   <td>9.9103</td>  <td>0.0000</td> <td>0.2165</td>  <td>0.3233</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-dob_lag30_count</th>        <td>-0.3970</td>  <td>0.2140</td>   <td>-1.8551</td> <td>0.0636</td> <td>-0.8164</td> <td>0.0224</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name-dob_lag30_count</th>       <td>4.2413</td>   <td>0.1264</td>   <td>33.5541</td> <td>0.0000</td> <td>3.9936</td>  <td>4.4891</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn_lag30_count</th>            <td>-0.0172</td>  <td>0.0206</td>   <td>-0.8369</td> <td>0.4026</td> <td>-0.0576</td> <td>0.0231</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-name-dob_lag30_count</th>   <td>-2.1605</td>  <td>0.2284</td>   <td>-9.4589</td> <td>0.0000</td> <td>-2.6082</td> <td>-1.7128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-firstname_lag30_count</th>  <td>-0.7780</td>  <td>0.2279</td>   <td>-3.4146</td> <td>0.0006</td> <td>-1.2246</td> <td>-0.3314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-lastname_lag30_count</th>   <td>-2.5530</td>  <td>0.2617</td>   <td>-9.7544</td> <td>0.0000</td> <td>-3.0660</td> <td>-2.0400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-name_lag30_count</th>       <td>1.9694</td>   <td>0.4030</td>   <td>4.8866</td>  <td>0.0000</td> <td>1.1795</td>  <td>2.7593</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr-homephone_#days_since</th> <td>0.0047</td>   <td>0.0001</td>   <td>38.0814</td> <td>0.0000</td> <td>0.0045</td>  <td>0.0050</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>addr-homephone_lag14_count</th> <td>-1.0117</td>  <td>0.0340</td>  <td>-29.7836</td> <td>0.0000</td> <td>-1.0782</td> <td>-0.9451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn-dob_#days_since</th>        <td>-0.0335</td>  <td>0.0008</td>  <td>-44.5820</td> <td>0.0000</td> <td>-0.0349</td> <td>-0.0320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>name-dob_#days_since</th>       <td>0.0279</td>   <td>0.0007</td>   <td>38.2680</td> <td>0.0000</td> <td>0.0265</td>  <td>0.0294</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ssn_#days_since</th>            <td>0.0018</td>   <td>0.0002</td>   <td>9.9697</td>  <td>0.0000</td> <td>0.0014</td>  <td>0.0021</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                              Results: Logit\n",
       "===========================================================================\n",
       "Model:                  Logit              Pseudo R-squared:   0.221       \n",
       "Dependent Variable:     y                  AIC:                1353728.1176\n",
       "Date:                   2020-03-07 21:37   BIC:                1354029.1562\n",
       "No. Observations:       1253614            Log-Likelihood:     -6.7684e+05 \n",
       "Df Model:               24                 LL-Null:            -8.6894e+05 \n",
       "Df Residuals:           1253589            LLR p-value:        0.0000      \n",
       "Converged:              1.0000             Scale:              1.0000      \n",
       "No. Iterations:         11.0000                                            \n",
       "---------------------------------------------------------------------------\n",
       "                            Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "---------------------------------------------------------------------------\n",
       "addr_lag30_count            0.5583   0.0346  16.1230 0.0000  0.4905  0.6262\n",
       "address_lag30_count        -0.3860   0.0246 -15.7114 0.0000 -0.4341 -0.3378\n",
       "addr_#days_since           -0.0020   0.0002 -11.1101 0.0000 -0.0023 -0.0016\n",
       "address_#days_since        -0.0050   0.0001 -39.3055 0.0000 -0.0053 -0.0048\n",
       "address_lag14_count         0.3231   0.0439   7.3631 0.0000  0.2371  0.4092\n",
       "addr_lag14_count            0.8304   0.0561  14.7904 0.0000  0.7204  0.9405\n",
       "address_lag7_count         -0.9523   0.0720 -13.2276 0.0000 -1.0934 -0.8112\n",
       "addr_lag7_count             1.4539   0.0771  18.8612 0.0000  1.3028  1.6050\n",
       "address_lag3_count         -0.3772   0.1217  -3.0988 0.0019 -0.6158 -0.1386\n",
       "addr_lag3_count             1.3437   0.1260  10.6639 0.0000  1.0968  1.5907\n",
       "address_lag1_count         -2.8448   0.3949  -7.2029 0.0000 -3.6188 -2.0707\n",
       "addr_lag1_count             0.9755   0.3957   2.4652 0.0137  0.1999  1.7511\n",
       "addr-homephone_lag30_count  0.2699   0.0272   9.9103 0.0000  0.2165  0.3233\n",
       "ssn-dob_lag30_count        -0.3970   0.2140  -1.8551 0.0636 -0.8164  0.0224\n",
       "name-dob_lag30_count        4.2413   0.1264  33.5541 0.0000  3.9936  4.4891\n",
       "ssn_lag30_count            -0.0172   0.0206  -0.8369 0.4026 -0.0576  0.0231\n",
       "ssn-name-dob_lag30_count   -2.1605   0.2284  -9.4589 0.0000 -2.6082 -1.7128\n",
       "ssn-firstname_lag30_count  -0.7780   0.2279  -3.4146 0.0006 -1.2246 -0.3314\n",
       "ssn-lastname_lag30_count   -2.5530   0.2617  -9.7544 0.0000 -3.0660 -2.0400\n",
       "ssn-name_lag30_count        1.9694   0.4030   4.8866 0.0000  1.1795  2.7593\n",
       "addr-homephone_#days_since  0.0047   0.0001  38.0814 0.0000  0.0045  0.0050\n",
       "addr-homephone_lag14_count -1.0117   0.0340 -29.7836 0.0000 -1.0782 -0.9451\n",
       "ssn-dob_#days_since        -0.0335   0.0008 -44.5820 0.0000 -0.0349 -0.0320\n",
       "name-dob_#days_since        0.0279   0.0007  38.2680 0.0000  0.0265  0.0294\n",
       "ssn_#days_since             0.0018   0.0002   9.9697 0.0000  0.0014  0.0021\n",
       "===========================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model2 = sm.Logit(y_fdr_train_os, fdr_train_os)\n",
    "result2 = logit_model2.fit(maxiter=5000)\n",
    "result2.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 100% on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[448251, 178556],\n",
       "       [216674, 410133]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob2 = result2.predict(fdr_train_os)\n",
    "result_pred2 = (result_prob2 > 0.5)\n",
    "confusion_matrix(y_fdr_train_os, result_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6543210270466029"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "410133/(410133+216674)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 100% on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112035,  44668],\n",
       "       [   802,   1495]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob2_test = result2.predict(fdr_test)\n",
    "result_pred2_test = (result_prob2_test > 0.5)\n",
    "confusion_matrix(y_fdr_test, result_pred2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6508489333913801"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1495/(1495+802)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model with oversampled fraud records and features selected by wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484021\n",
      "         Iterations 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>     <td>0.302</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>        <td>1213601.4698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-07 21:26</td>       <td>BIC:</td>        <td>1213902.5083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>1253614</td>      <td>Log-Likelihood:</td>   <td>-6.0678e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>24</td>            <td>LL-Null:</td>       <td>-8.6894e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>1253589</td>       <td>LLR p-value:</td>       <td>0.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>          <td>1.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>12.0000</td>             <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>    <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>0.5927</td>   <td>0.0176</td>   <td>33.6961</td>  <td>0.0000</td> <td>0.5583</td>  <td>0.6272</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>-0.4552</td>  <td>0.0368</td>  <td>-12.3625</td>  <td>0.0000</td> <td>-0.5274</td> <td>-0.3830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>0.2237</td>   <td>0.0630</td>   <td>3.5538</td>   <td>0.0004</td> <td>0.1003</td>  <td>0.3471</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>0.1442</td>   <td>0.0649</td>   <td>2.2211</td>   <td>0.0263</td> <td>0.0169</td>  <td>0.2714</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>0.5765</td>   <td>0.0359</td>   <td>16.0480</td>  <td>0.0000</td> <td>0.5061</td>  <td>0.6469</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>0.4089</td>   <td>0.1028</td>   <td>3.9794</td>   <td>0.0001</td> <td>0.2075</td>  <td>0.6103</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>1.2210</td>   <td>0.1087</td>   <td>11.2326</td>  <td>0.0000</td> <td>1.0079</td>  <td>1.4340</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>-1.6134</td>  <td>0.2593</td>   <td>-6.2220</td>  <td>0.0000</td> <td>-2.1217</td> <td>-1.1052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>1.0681</td>   <td>0.1037</td>   <td>10.3040</td>  <td>0.0000</td> <td>0.8649</td>  <td>1.2713</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>2.2051</td>   <td>0.2861</td>   <td>7.7085</td>   <td>0.0000</td> <td>1.6445</td>  <td>2.7658</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>1.3063</td>   <td>0.2771</td>   <td>4.7142</td>   <td>0.0000</td> <td>0.7632</td>  <td>1.8494</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>-2.3154</td>  <td>0.2817</td>   <td>-8.2193</td>  <td>0.0000</td> <td>-2.8676</td> <td>-1.7633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>-0.0409</td>  <td>0.0010</td>  <td>-40.6604</td>  <td>0.0000</td> <td>-0.0428</td> <td>-0.0389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>-0.4573</td>  <td>0.0410</td>  <td>-11.1410</td>  <td>0.0000</td> <td>-0.5377</td> <td>-0.3768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>0.0411</td>   <td>0.0010</td>   <td>40.9455</td>  <td>0.0000</td> <td>0.0392</td>  <td>0.0431</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>-0.3125</td>  <td>0.0016</td>  <td>-191.5079</td> <td>0.0000</td> <td>-0.3157</td> <td>-0.3093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>-0.3239</td>  <td>0.0082</td>  <td>-39.3934</td>  <td>0.0000</td> <td>-0.3400</td> <td>-0.3078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>-0.5487</td>  <td>0.0582</td>   <td>-9.4266</td>  <td>0.0000</td> <td>-0.6628</td> <td>-0.4346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>0.2080</td>   <td>0.0014</td>  <td>145.2142</td>  <td>0.0000</td> <td>0.2052</td>  <td>0.2108</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>-0.3126</td>  <td>0.2901</td>   <td>-1.0778</td>  <td>0.2811</td> <td>-0.8811</td> <td>0.2559</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>3.4320</td>   <td>0.7095</td>   <td>4.8371</td>   <td>0.0000</td> <td>2.0414</td>  <td>4.8226</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>-3.9117</td>  <td>0.7132</td>   <td>-5.4848</td>  <td>0.0000</td> <td>-5.3096</td> <td>-2.5139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>-6.1852</td>  <td>0.8516</td>   <td>-7.2632</td>  <td>0.0000</td> <td>-7.8543</td> <td>-4.5162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>-0.9151</td>  <td>0.7752</td>   <td>-1.1805</td>  <td>0.2378</td> <td>-2.4344</td> <td>0.6042</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>9.0586</td>   <td>1.3745</td>   <td>6.5903</td>   <td>0.0000</td> <td>6.3646</td>  <td>11.7527</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "===================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.302       \n",
       "Dependent Variable: y                AIC:              1213601.4698\n",
       "Date:               2020-03-07 21:26 BIC:              1213902.5083\n",
       "No. Observations:   1253614          Log-Likelihood:   -6.0678e+05 \n",
       "Df Model:           24               LL-Null:          -8.6894e+05 \n",
       "Df Residuals:       1253589          LLR p-value:      0.0000      \n",
       "Converged:          1.0000           Scale:            1.0000      \n",
       "No. Iterations:     12.0000                                        \n",
       "---------------------------------------------------------------------\n",
       "           Coef.    Std.Err.       z       P>|z|     [0.025    0.975]\n",
       "---------------------------------------------------------------------\n",
       "x1         0.5927     0.0176     33.6961   0.0000    0.5583    0.6272\n",
       "x2        -0.4552     0.0368    -12.3625   0.0000   -0.5274   -0.3830\n",
       "x3         0.2237     0.0630      3.5538   0.0004    0.1003    0.3471\n",
       "x4         0.1442     0.0649      2.2211   0.0263    0.0169    0.2714\n",
       "x5         0.5765     0.0359     16.0480   0.0000    0.5061    0.6469\n",
       "x6         0.4089     0.1028      3.9794   0.0001    0.2075    0.6103\n",
       "x7         1.2210     0.1087     11.2326   0.0000    1.0079    1.4340\n",
       "x8        -1.6134     0.2593     -6.2220   0.0000   -2.1217   -1.1052\n",
       "x9         1.0681     0.1037     10.3040   0.0000    0.8649    1.2713\n",
       "x10        2.2051     0.2861      7.7085   0.0000    1.6445    2.7658\n",
       "x11        1.3063     0.2771      4.7142   0.0000    0.7632    1.8494\n",
       "x12       -2.3154     0.2817     -8.2193   0.0000   -2.8676   -1.7633\n",
       "x13       -0.0409     0.0010    -40.6604   0.0000   -0.0428   -0.0389\n",
       "x14       -0.4573     0.0410    -11.1410   0.0000   -0.5377   -0.3768\n",
       "x15        0.0411     0.0010     40.9455   0.0000    0.0392    0.0431\n",
       "x16       -0.3125     0.0016   -191.5079   0.0000   -0.3157   -0.3093\n",
       "x17       -0.3239     0.0082    -39.3934   0.0000   -0.3400   -0.3078\n",
       "x18       -0.5487     0.0582     -9.4266   0.0000   -0.6628   -0.4346\n",
       "x19        0.2080     0.0014    145.2142   0.0000    0.2052    0.2108\n",
       "x20       -0.3126     0.2901     -1.0778   0.2811   -0.8811    0.2559\n",
       "x21        3.4320     0.7095      4.8371   0.0000    2.0414    4.8226\n",
       "x22       -3.9117     0.7132     -5.4848   0.0000   -5.3096   -2.5139\n",
       "x23       -6.1852     0.8516     -7.2632   0.0000   -7.8543   -4.5162\n",
       "x24       -0.9151     0.7752     -1.1805   0.2378   -2.4344    0.6042\n",
       "x25        9.0586     1.3745      6.5903   0.0000    6.3646   11.7527\n",
       "===================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model1 = sm.Logit(y_train_os, x_train_os)\n",
    "result1 = logit_model1.fit(maxiter=5000)\n",
    "result1.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Fraud Detection Rate 100% on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[605660,  21147],\n",
       "       [277041, 349766]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob1 = result1.predict(x_train_os)\n",
    "result_pred1 = (result_prob1 > 0.5)\n",
    "confusion_matrix(y_train_os, result_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.558012274910778"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "349766/(349766+277041)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - Fraud Detection Rate 100% on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151514,   5189],\n",
       "       [  1007,   1290]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob1_test = result1.predict(x_test)\n",
    "result_pred1_test = (result_prob1_test > 0.5)\n",
    "confusion_matrix(y_test, result_pred1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5616020896821942"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1290/(1290+1007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 3% training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05999773454986942"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argsort(result_prob1)\n",
    "y_train_sorted1 = np.take_along_axis(y_train_os, ind, axis=0)\n",
    "result_prob1_sorted = np.take_along_axis(result_prob1, ind, axis=0)\n",
    "y_train_sorted1_3per = y_train_sorted1[-int(len(y_train_sorted1)*0.03):-1]\n",
    "y_train_sorted1_3per_fraud = y_train_sorted1_3per[y_train_sorted1_3per==1]\n",
    "y_train_os_fraud = y_train_os[y_train_os==1]\n",
    "len(y_train_sorted1_3per_fraud)/len(y_train_os_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 3% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5476708750544188"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argsort(result_prob1_test)\n",
    "y_test_sorted1 = np.take_along_axis(y_test, ind, axis=0)\n",
    "result_prob1_test_sorted = np.take_along_axis(result_prob1_test, ind, axis=0)\n",
    "y_test_sorted1_3per = y_test_sorted1[-int(len(y_test_sorted1)*0.03):-1]\n",
    "y_test_sorted1_3per_fraud = y_test_sorted1_3per[y_test_sorted1_3per==1]\n",
    "y_test_fraud = y_test[y_test==1]\n",
    "len(y_test_sorted1_3per_fraud)/len(y_test_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model with features selected by wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.050833\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.327</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>         <td>y</td>              <td>AIC:</td>        <td>64708.5905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-07 21:46</td>       <td>BIC:</td>        <td>64992.6642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>635996</td>       <td>Log-Likelihood:</td>    <td>-32329.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>24</td>            <td>LL-Null:</td>        <td>-48058.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>635971</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>9.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>    <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>1.2264</td>   <td>0.0558</td>   <td>21.9737</td>  <td>0.0000</td> <td>1.1170</td>  <td>1.3358</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>-1.6605</td>  <td>0.0974</td>  <td>-17.0502</td>  <td>0.0000</td> <td>-1.8513</td> <td>-1.4696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>1.7565</td>   <td>0.2217</td>   <td>7.9221</td>   <td>0.0000</td> <td>1.3220</td>  <td>2.1911</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>-1.7642</td>  <td>0.2093</td>   <td>-8.4280</td>  <td>0.0000</td> <td>-2.1745</td> <td>-1.3539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>0.4007</td>   <td>0.0510</td>   <td>7.8506</td>   <td>0.0000</td> <td>0.3006</td>  <td>0.5007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>0.6325</td>   <td>0.4591</td>   <td>1.3777</td>   <td>0.1683</td> <td>-0.2673</td> <td>1.5324</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>0.9439</td>   <td>0.4619</td>   <td>2.0434</td>   <td>0.0410</td> <td>0.0386</td>  <td>1.8493</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>-1.1094</td>  <td>0.4534</td>   <td>-2.4470</td>  <td>0.0144</td> <td>-1.9979</td> <td>-0.2208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>0.6861</td>   <td>0.1927</td>   <td>3.5598</td>   <td>0.0004</td> <td>0.3083</td>  <td>1.0638</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>2.4946</td>   <td>0.5519</td>   <td>4.5200</td>   <td>0.0000</td> <td>1.4129</td>  <td>3.5763</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>0.7404</td>   <td>0.5329</td>   <td>1.3893</td>   <td>0.1647</td> <td>-0.3041</td> <td>1.7849</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>-2.1210</td>  <td>0.5851</td>   <td>-3.6247</td>  <td>0.0003</td> <td>-3.2679</td> <td>-0.9741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>-0.0235</td>  <td>0.0013</td>  <td>-17.5062</td>  <td>0.0000</td> <td>-0.0261</td> <td>-0.0209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th> <td>-0.3234</td>  <td>0.0865</td>   <td>-3.7396</td>  <td>0.0002</td> <td>-0.4929</td> <td>-0.1539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th> <td>0.0252</td>   <td>0.0013</td>   <td>18.7802</td>  <td>0.0000</td> <td>0.0226</td>  <td>0.0278</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th> <td>-0.5601</td>  <td>0.0037</td>  <td>-152.3492</td> <td>0.0000</td> <td>-0.5673</td> <td>-0.5529</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th> <td>-0.4168</td>  <td>0.0471</td>   <td>-8.8469</td>  <td>0.0000</td> <td>-0.5091</td> <td>-0.3244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th> <td>-0.0911</td>  <td>0.1005</td>   <td>-0.9060</td>  <td>0.3649</td> <td>-0.2880</td> <td>0.1059</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th> <td>0.2251</td>   <td>0.0073</td>   <td>30.9293</td>  <td>0.0000</td> <td>0.2109</td>  <td>0.2394</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th> <td>-0.1487</td>  <td>0.4124</td>   <td>-0.3606</td>  <td>0.7184</td> <td>-0.9570</td> <td>0.6596</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th> <td>1.2063</td>   <td>1.1920</td>   <td>1.0119</td>   <td>0.3116</td> <td>-1.1301</td> <td>3.5426</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th> <td>-2.9034</td>  <td>1.4610</td>   <td>-1.9873</td>  <td>0.0469</td> <td>-5.7668</td> <td>-0.0400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th> <td>-1.3523</td>  <td>1.1444</td>   <td>-1.1816</td>  <td>0.2374</td> <td>-3.5953</td> <td>0.8908</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th> <td>0.5127</td>   <td>1.3517</td>   <td>0.3793</td>   <td>0.7045</td> <td>-2.1367</td> <td>3.1621</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th> <td>3.4640</td>   <td>2.2537</td>   <td>1.5370</td>   <td>0.1243</td> <td>-0.9532</td> <td>7.8811</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "=================================================================\n",
       "Model:              Logit            Pseudo R-squared: 0.327     \n",
       "Dependent Variable: y                AIC:              64708.5905\n",
       "Date:               2020-03-07 21:46 BIC:              64992.6642\n",
       "No. Observations:   635996           Log-Likelihood:   -32329.   \n",
       "Df Model:           24               LL-Null:          -48058.   \n",
       "Df Residuals:       635971           LLR p-value:      0.0000    \n",
       "Converged:          1.0000           Scale:            1.0000    \n",
       "No. Iterations:     9.0000                                       \n",
       "-------------------------------------------------------------------\n",
       "         Coef.    Std.Err.       z       P>|z|     [0.025    0.975]\n",
       "-------------------------------------------------------------------\n",
       "x1       1.2264     0.0558     21.9737   0.0000    1.1170    1.3358\n",
       "x2      -1.6605     0.0974    -17.0502   0.0000   -1.8513   -1.4696\n",
       "x3       1.7565     0.2217      7.9221   0.0000    1.3220    2.1911\n",
       "x4      -1.7642     0.2093     -8.4280   0.0000   -2.1745   -1.3539\n",
       "x5       0.4007     0.0510      7.8506   0.0000    0.3006    0.5007\n",
       "x6       0.6325     0.4591      1.3777   0.1683   -0.2673    1.5324\n",
       "x7       0.9439     0.4619      2.0434   0.0410    0.0386    1.8493\n",
       "x8      -1.1094     0.4534     -2.4470   0.0144   -1.9979   -0.2208\n",
       "x9       0.6861     0.1927      3.5598   0.0004    0.3083    1.0638\n",
       "x10      2.4946     0.5519      4.5200   0.0000    1.4129    3.5763\n",
       "x11      0.7404     0.5329      1.3893   0.1647   -0.3041    1.7849\n",
       "x12     -2.1210     0.5851     -3.6247   0.0003   -3.2679   -0.9741\n",
       "x13     -0.0235     0.0013    -17.5062   0.0000   -0.0261   -0.0209\n",
       "x14     -0.3234     0.0865     -3.7396   0.0002   -0.4929   -0.1539\n",
       "x15      0.0252     0.0013     18.7802   0.0000    0.0226    0.0278\n",
       "x16     -0.5601     0.0037   -152.3492   0.0000   -0.5673   -0.5529\n",
       "x17     -0.4168     0.0471     -8.8469   0.0000   -0.5091   -0.3244\n",
       "x18     -0.0911     0.1005     -0.9060   0.3649   -0.2880    0.1059\n",
       "x19      0.2251     0.0073     30.9293   0.0000    0.2109    0.2394\n",
       "x20     -0.1487     0.4124     -0.3606   0.7184   -0.9570    0.6596\n",
       "x21      1.2063     1.1920      1.0119   0.3116   -1.1301    3.5426\n",
       "x22     -2.9034     1.4610     -1.9873   0.0469   -5.7668   -0.0400\n",
       "x23     -1.3523     1.1444     -1.1816   0.2374   -3.5953    0.8908\n",
       "x24      0.5127     1.3517      0.3793   0.7045   -2.1367    3.1621\n",
       "x25      3.4640     2.2537      1.5370   0.1243   -0.9532    7.8811\n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model = sm.Logit(y_train, x_train)\n",
    "result = logit_model.fit(maxiter=5000)\n",
    "result.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 100% on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[626458,    349],\n",
       "       [  6040,   3149]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob = result.predict(x_train)\n",
    "result_pred = (result_prob > 0.5)\n",
    "confusion_matrix(y_train, result_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3426923495483731"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3149/(3149+6040)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 100% on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[156614,     89],\n",
       "       [  1511,    786]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_prob_test = result.predict(x_test)\n",
    "result_pred_test = (result_prob_test > 0.5)\n",
    "confusion_matrix(y_test, result_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34218545929473226"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "786/(786+1511)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 3% training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.517901839155512"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argsort(result_prob)\n",
    "y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "result_prob_sorted = np.take_along_axis(result_prob, ind, axis=0)\n",
    "y_train_sorted_3per = y_train_sorted[-int(len(y_train_sorted)*0.03):-1]\n",
    "y_train_sorted_3per_fraud = y_train_sorted_3per[y_train_sorted_3per==1]\n",
    "y_train_fraud = y_train[y_train==1]\n",
    "len(y_train_sorted_3per_fraud)/len(y_train_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### - FDR 3% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5267740531127557"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.argsort(result_prob_test)\n",
    "y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "result_prob_test_sorted = np.take_along_axis(result_prob_test, ind, axis=0)\n",
    "y_test_sorted_3per = y_test_sorted[-int(len(y_test_sorted)*0.03):-1]\n",
    "y_test_sorted_3per_fraud = y_test_sorted_3per[y_test_sorted_3per==1]\n",
    "y_test_fraud = y_test[y_test==1]\n",
    "len(y_test_sorted_3per_fraud)/len(y_test_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for n in range(3,11):\n",
    "    fdr = 0\n",
    "    for i in range(5):\n",
    "        NN = MLPRegressor(hidden_layer_sizes=(n,),activation='logistic',solver='adam',\n",
    "                              learning_rate='adaptive',max_iter=10000,learning_rate_init=.01,alpha=.01)\n",
    "        NN.fit(x_train,y_train)\n",
    "        NN_train_pred = NN.predict(x_train)\n",
    "        NN_test_pred = NN.predict(x_test)\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.3):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = y_train[y_train==1]\n",
    "        fdr += len(NN_y_train_sorted_3per_fraud)/len(y_train_fraud)\n",
    "        i += 1\n",
    "    avg_fdr=fdr/5\n",
    "    print(f'With {n} layers, FDR at 3%:', avg_fdr)\n",
    "    n += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "for n in range(3,11):\n",
    "    fdr = 0\n",
    "    for i in range(5):\n",
    "        NN = MLPRegressor(hidden_layer_sizes=(n,),activation='logistic',solver='adam',\n",
    "                              learning_rate='adaptive',max_iter=10000,learning_rate_init=.01,alpha=.01)\n",
    "        NN.fit(x_test,y_test)\n",
    "        NN_test_pred = NN.predict(x_test)\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.3):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = y_test[y_test==1]\n",
    "        fdr += len(NN_y_test_sorted_3per_fraud)/len(y_test_fraud)\n",
    "        i += 1\n",
    "    avg_fdr=fdr/5\n",
    "    print(f'With {n} layers, FDR at 3%:', avg_fdr)\n",
    "    n += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 3 layers, FDR at 3%: 0.5471759712699967\n",
      "With 4 layers, FDR at 3%: 0.6750462509522255\n",
      "With 5 layers, FDR at 3%: 0.6876700402655349\n",
      "With 6 layers, FDR at 3%: 0.6923495483730547\n",
      "With 7 layers, FDR at 3%: 0.5254108172815323\n"
     ]
    }
   ],
   "source": [
    "for n in range(3,8):\n",
    "    NN = MLPRegressor(hidden_layer_sizes=(n,),activation='logistic',solver='adam',\n",
    "                          learning_rate='adaptive',max_iter=10000,learning_rate_init=.01,alpha=.01)\n",
    "    NN.fit(x_train,y_train)\n",
    "    NN_train_pred = NN.predict(x_train)\n",
    "    NN_test_pred = NN.predict(x_test)\n",
    "    ind = np.argsort(NN_train_pred)\n",
    "    NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "    NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "    NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.3):-1]\n",
    "    NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "    y_train_fraud = y_train[y_train==1]\n",
    "    print(f'With {n} layers, FDR at 3%:', len(NN_y_train_sorted_3per_fraud)/len(y_train_fraud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 250 layers, FDR at 3%: 0.5096310806398955\n"
     ]
    }
   ],
   "source": [
    "#for n in range(8,11):\n",
    "NN = MLPRegressor(hidden_layer_sizes=(9,),activation='logistic',solver='adam',\n",
    "                      learning_rate='adaptive',max_iter=10000,learning_rate_init=.01,alpha=.01)\n",
    "NN.fit(x_train,y_train)\n",
    "NN_train_pred = NN.predict(x_train)\n",
    "NN_test_pred = NN.predict(x_test)\n",
    "ind = np.argsort(NN_train_pred)\n",
    "NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "y_train_fraud = y_train[y_train==1]\n",
    "print(f'With {n} layers, FDR at 3%:', len(NN_y_train_sorted_3per_fraud)/len(y_train_fraud))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0\n",
      "20 1\n",
      "20 2\n",
      "20 3\n",
      "20 4\n",
      "With 20 trees, FDR at 3%: 0.8001088257699424\n",
      "30 0\n",
      "30 1\n",
      "30 2\n",
      "30 3\n",
      "30 4\n",
      "With 30 trees, FDR at 3%: 0.8005005985417346\n",
      "40 0\n",
      "40 1\n",
      "40 2\n",
      "40 3\n",
      "40 4\n",
      "With 40 trees, FDR at 3%: 0.8005005985417346\n",
      "50 0\n",
      "50 1\n",
      "50 2\n",
      "50 3\n",
      "50 4\n",
      "With 50 trees, FDR at 3%: 0.8008706061595385\n",
      "60 0\n",
      "60 1\n",
      "60 2\n",
      "60 3\n",
      "60 4\n",
      "With 60 trees, FDR at 3%: 0.8008488410055502\n",
      "70 0\n",
      "70 1\n",
      "70 2\n",
      "70 3\n",
      "70 4\n",
      "With 70 trees, FDR at 3%: 0.8010011970834693\n",
      "80 0\n",
      "80 1\n",
      "80 2\n",
      "80 3\n",
      "80 4\n",
      "With 80 trees, FDR at 3%: 0.8010011970834693\n",
      "90 0\n",
      "90 1\n",
      "90 2\n",
      "90 3\n",
      "90 4\n",
      "With 90 trees, FDR at 3%: 0.8008706061595385\n",
      "100 0\n",
      "100 1\n",
      "100 2\n",
      "100 3\n",
      "100 4\n",
      "With 100 trees, FDR at 3%: 0.8010011970834693\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for n in range(20,110,10):\n",
    "    fdr = 0\n",
    "    for i in range (5):\n",
    "        RF = RandomForestRegressor(n_estimators=n)\n",
    "        RF.fit(x_train, y_train)\n",
    "        RF_train_pred = RF.predict(x_train)\n",
    "        RF_test_pred = RF.predict(x_test)\n",
    "        ind = np.argsort(RF_train_pred)\n",
    "        RF_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        RF_train_pred_sorted = np.take_along_axis(RF_train_pred, ind, axis=0)\n",
    "        RF_y_train_sorted_3per = RF_y_train_sorted[-int(len(RF_y_train_sorted)*0.3):-1]\n",
    "        RF_y_train_sorted_3per_fraud = RF_y_train_sorted_3per[RF_y_train_sorted_3per==1]\n",
    "        y_train_fraud = y_train[y_train==1]\n",
    "        fdr += len(RF_y_train_sorted_3per_fraud)/len(y_train_fraud)\n",
    "        print(n, i)\n",
    "        i += 1\n",
    "    \n",
    "    avg_fdr = fdr/5\n",
    "    print(f'With {n} trees, FDR at 3%:', avg_fdr)\n",
    "    n += 10\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20 trees, FDR at 3%: 0.8884632128863735\n",
      "With 30 trees, FDR at 3%: 0.8901175446234217\n",
      "With 40 trees, FDR at 3%: 0.8901175446234217\n",
      "With 50 trees, FDR at 3%: 0.8905528950805397\n",
      "With 60 trees, FDR at 3%: 0.8906399651719635\n",
      "With 70 trees, FDR at 3%: 0.8907270352633871\n",
      "With 80 trees, FDR at 3%: 0.8908141053548106\n",
      "With 90 trees, FDR at 3%: 0.8909011754462343\n",
      "With 100 trees, FDR at 3%: 0.8908141053548106\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for n in range(20,110,10):\n",
    "    fdr = 0\n",
    "    for i in range (5):\n",
    "        RF = RandomForestRegressor(n_estimators=n)\n",
    "        RF.fit(x_test, y_test)\n",
    "        RF_test_pred = RF.predict(x_test)\n",
    "        ind = np.argsort(RF_test_pred)\n",
    "        RF_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        RF_test_pred_sorted = np.take_along_axis(RF_test_pred, ind, axis=0)\n",
    "        RF_y_test_sorted_3per = RF_y_test_sorted[-int(len(RF_y_test_sorted)*0.3):-1]\n",
    "        RF_y_test_sorted_3per_fraud = RF_y_test_sorted_3per[RF_y_test_sorted_3per==1]\n",
    "        y_test_fraud = y_test[y_test==1]\n",
    "        fdr += len(RF_y_test_sorted_3per_fraud)/len(y_test_fraud)\n",
    "        i += 1\n",
    "    avg_fdr = fdr/5\n",
    "    print(f'With {n} trees, FDR at 3%:', avg_fdr)\n",
    "    n += 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 80 trees, FDR at 3%: 0.8010664925454347\n",
      "With 85 trees, FDR at 3%: 0.8009576667754924\n",
      "With 90 trees, FDR at 3%: 0.8010664925454347\n",
      "With 95 trees, FDR at 3%: 0.8008488410055501\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for n in range(80,100,5):\n",
    "    RF = RandomForestRegressor(n_estimators=n)\n",
    "    RF.fit(x_train, y_train)\n",
    "    RF_train_pred = RF.predict(x_train)\n",
    "    RF_test_pred = RF.predict(x_test)\n",
    "    ind = np.argsort(RF_train_pred)\n",
    "    RF_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "    RF_train_pred_sorted = np.take_along_axis(RF_train_pred, ind, axis=0)\n",
    "    RF_y_train_sorted_3per = RF_y_train_sorted[-int(len(RF_y_train_sorted)*0.3):-1]\n",
    "    RF_y_train_sorted_3per_fraud = RF_y_train_sorted_3per[RF_y_train_sorted_3per==1]\n",
    "    y_train_fraud = y_train[y_train==1]\n",
    "    print(f'With {n} trees, FDR at 3%:', len(RF_y_train_sorted_3per_fraud)/len(y_train_fraud))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 200 trees, FDR at 3%: 0.7708129285014691\n",
      "With 210 trees, FDR at 3%: 0.7709652845793885\n",
      "With 220 trees, FDR at 3%: 0.7732723909021656\n",
      "With 230 trees, FDR at 3%: 0.7750788986832081\n",
      "With 240 trees, FDR at 3%: 0.773381216672108\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-b3d4b4179091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min_samples_split'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mGB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mGB_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mGB_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for n in range(200,300,10):\n",
    "    fdr = 0\n",
    "    for i in range (5):\n",
    "        params = {'n_estimators':n, 'max_depth':10, 'min_samples_split':10, 'learning_rate':.2, 'loss':'ls'}\n",
    "        GB = GradientBoostingRegressor(**params)\n",
    "        GB.fit(x_train, y_train)\n",
    "        GB_train_pred = GB.predict(x_train)\n",
    "        GB_test_pred = GB.predict(x_test)\n",
    "        ind = np.argsort(GB_train_pred)\n",
    "        GB_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        GB_train_pred_sorted = np.take_along_axis(GB_train_pred, ind, axis=0)\n",
    "        GB_y_train_sorted_3per = GB_y_train_sorted[-int(len(GB_y_train_sorted)*0.3):-1]\n",
    "        GB_y_train_sorted_3per_fraud = GB_y_train_sorted_3per[GB_y_train_sorted_3per==1]\n",
    "        y_train_fraud = y_train[y_train==1]\n",
    "        fdr += len(GB_y_train_sorted_3per_fraud)/len(y_train_fraud)\n",
    "        i += 1\n",
    "    \n",
    "    avg_fdr = fdr/5\n",
    "    print(f'With {n} trees, FDR at 3%:', avg_fdr)\n",
    "    n += 10\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "for n in range(200,300,10):\n",
    "    fdr = 0\n",
    "    for i in range (5):\n",
    "        params = {'n_estimators':n, 'max_depth':10, 'min_samples_split':10, 'learning_rate':.2, 'loss':'ls'}\n",
    "        GB = GradientBoostingRegressor(**params)\n",
    "        GB.fit(x_test, y_test)\n",
    "        GB_test_pred = GB.predict(x_test)\n",
    "        ind = np.argsort(GB_test_pred)\n",
    "        GB_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        GB_test_pred_sorted = np.take_along_axis(GB_test_pred, ind, axis=0)\n",
    "        GB_y_test_sorted_3per = GB_y_test_sorted[-int(len(GB_y_test_sorted)*0.3):-1]\n",
    "        GB_y_test_sorted_3per_fraud = GB_y_test_sorted_3per[GB_y_test_sorted_3per==1]\n",
    "        y_test_fraud = y_test[y_test==1]\n",
    "        fdr += len(GB_y_test_sorted_3per_fraud)/len(y_test_fraud)\n",
    "        i += 1\n",
    "    \n",
    "    avg_fdr = fdr/5\n",
    "    print(f'With {n} trees, FDR at 3%:', avg_fdr)\n",
    "    n += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
